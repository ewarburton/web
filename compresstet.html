<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EDO Audio Converter (Alpha 1.0)</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background: #1a1a1a;
            color: #e0e0e0;
        }
        h1 {
            text-align: center;
            color: #4a9eff;
        }
        .container {
            background: #2a2a2a;
            padding: 25px;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.3);
        }
        .input-group {
            margin: 20px 0;
        }
        label {
            display: block;
            margin-bottom: 8px;
            font-weight: 600;
            color: #b0b0b0;
        }
        input[type="file"],
        input[type="number"] {
            width: 100%;
            padding: 10px;
            border: 2px solid #444;
            border-radius: 5px;
            font-size: 16px;
            background: #1a1a1a;
            color: #e0e0e0;
            box-sizing: border-box;
        }
        input[type="number"]:focus,
        input[type="file"]:focus {
            outline: none;
            border-color: #4a9eff;
        }
        .edo-inputs {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 15px;
        }
        button {
            width: 100%;
            padding: 15px;
            background: #4a9eff;
            color: white;
            border: none;
            border-radius: 5px;
            font-size: 18px;
            font-weight: bold;
            cursor: pointer;
            margin-top: 20px;
            transition: background 0.3s;
        }
        button:hover {
            background: #3a7ecf;
        }
        button:disabled {
            background: #555;
            cursor: not-allowed;
        }
        video {
            width: 100%;
            margin: 20px 0;
            border-radius: 5px;
            display: none;
        }
        video.active {
            display: block;
        }
        .spectrogram-container {
            margin: 20px 0;
            display: none;
        }
        .spectrogram-container.active {
            display: block;
        }
        .spectrogram-label {
            font-weight: 600;
            color: #4a9eff;
            margin-bottom: 5px;
        }
        canvas {
            width: 100%;
            height: 200px;
            background: #000;
            border-radius: 5px;
            margin-bottom: 15px;
            image-rendering: pixelated;
        }
        .status {
            margin-top: 20px;
            padding: 15px;
            background: #333;
            border-radius: 5px;
            display: none;
        }
        .status.active {
            display: block;
        }
        .status.processing {
            border-left: 4px solid #ff9800;
        }
        .status.success {
            border-left: 4px solid #4caf50;
        }
        .status.error {
            border-left: 4px solid #f44336;
        }
        .info {
            margin-top: 30px;
            padding: 15px;
            background: #333;
            border-radius: 5px;
            border-left: 4px solid #4a9eff;
        }
        .info h3 {
            margin-top: 0;
            color: #4a9eff;
        }
        .info p {
            margin: 8px 0;
            line-height: 1.6;
        }
    </style>
</head>
<body>
    <h1>EDO Audio Converter (Alpha 1.0)</h1>
    
    <div class="container">
        <div class="input-group">
            <label for="videoInput">Select Video File:</label>
            <input type="file" id="videoInput" accept="video/*">
        </div>

        <video id="videoPlayer" controls></video>

        <div class="spectrogram-container" id="spectrogramContainer">
            <div class="spectrogram-label">Original Spectrogram:</div>
            <canvas id="originalSpectrogram"></canvas>
            <div class="spectrogram-label">Converted Spectrogram:</div>
            <canvas id="convertedSpectrogram"></canvas>
        </div>

        <div class="input-group">
            <label for="initialHz">Initial Hz (Reference Frequency):</label>
            <input type="number" id="initialHz" value="440" step="0.1" min="1">
        </div>

        <div class="input-group">
            <label for="scaleMaker">Scale Maker (comma-separated cents, optional):</label>
            <input type="text" id="scaleMaker" placeholder="e.g., 0,100,200,300,400,500,600,700,800,900,1000,1100,1200" style="width: 100%; padding: 10px; border: 2px solid #444; border-radius: 5px; font-size: 16px; background: #1a1a1a; color: #e0e0e0; box-sizing: border-box;">
            <small style="color: #888; margin-top: 5px; display: block;">Leave empty to use EDO. Enter scale steps in cents (e.g., "0,204,408,612,816,1020,1224" for Pythagorean JI whole tones)</small>
        </div>

        <div class="edo-inputs">
            <div class="input-group">
                <label for="fromTet">Change from (EDO):</label>
                <input type="number" id="fromTet" value="12" min="1" step="1">
            </div>
            <div class="input-group">
                <label for="toTet">To (EDO):</label>
                <input type="number" id="toTet" value="19" min="1" step="1">
            </div>
        </div>

        <div class="input-group">
            <label for="mode">Mode:</label>
            <select id="mode" style="width: 100%; padding: 10px; border: 2px solid #444; border-radius: 5px; font-size: 16px; background: #1a1a1a; color: #e0e0e0;">
                <option value="approximate">Approximate - Round to nearest pitch</option>
                <option value="scale">Scale - Transform by ratio (10-14 EDO only)</option>
            </select>
        </div>

        <button id="processBtn" disabled>Process Audio</button>

        <div id="status" class="status"></div>

        <div class="info">
            <h3>About This Tool</h3>
            <p><strong>How it works:</strong> This tool uses FFT with logarithmic frequency scaling to better match musical perception. It detects clusters of nearby frequencies (within 20 cents) using exponential weighting, then applies the selected mode.</p>
            <p><strong>Initial Hz:</strong> The reference frequency (typically A4 = 440 Hz).</p>
            <p><strong>Scale Maker:</strong> Optional custom scale in cents. Enter comma-separated values (e.g., "0,100,200,300,400,500,600,700,800,900,1000,1100,1200" for 12-EDO). Leave empty to use standard EDO. The scale automatically repeats each octave.</p>
            <p><strong>From EDO:</strong> Source equal temperament (default 12-EDO).</p>
            <p><strong>To EDO:</strong> Target equal temperament (e.g., 19-EDO, 24-EDO, 31-EDO, etc.). Ignored if using custom scale.</p>
            <p><strong>Modes:</strong></p>
            <p style="margin-left: 20px;"><strong>Approximate:</strong> Rounds each cluster to the nearest pitch in the target EDO or custom scale. Works for all conversions.</p>
            <p style="margin-left: 20px;"><strong>Scale:</strong> Transforms frequencies by the ratio fromEDO/toEDO. Converts 12x semitones to (fromEDO/toEDO) Ã— 12x semitones. Only works when both source and target are 10-14 EDO. Ignores custom scale.</p>
            <p><strong>Process:</strong> The spectrum is converted to logarithmic scale. Clusters within 20 cents are detected with exponential magnitude weighting. Each cluster is amplified logarithmically (+10dB for 10 frequencies, +20dB for 100) and processed according to the selected mode.</p>
        </div>
    </div>

    <script>
        const videoInput = document.getElementById('videoInput');
        const videoPlayer = document.getElementById('videoPlayer');
        const initialHzInput = document.getElementById('initialHz');
        const scaleMakerInput = document.getElementById('scaleMaker');
        const fromTetInput = document.getElementById('fromTet');
        const toTetInput = document.getElementById('toTet');
        const modeSelect = document.getElementById('mode');
        const processBtn = document.getElementById('processBtn');
        const statusDiv = document.getElementById('status');
        const spectrogramContainer = document.getElementById('spectrogramContainer');
        const originalCanvas = document.getElementById('originalSpectrogram');
        const convertedCanvas = document.getElementById('convertedSpectrogram');

        let audioContext;
        let videoFile;

        // Initialize Audio Context
        function initAudioContext() {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }
        }

        // Handle video file selection
        videoInput.addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (file) {
                videoFile = file;
                const url = URL.createObjectURL(file);
                videoPlayer.src = url;
                videoPlayer.classList.add('active');
                processBtn.disabled = false;
                showStatus('Video loaded. Ready to process.', 'success');
            }
        });

        // Show status message
        function showStatus(message, type = 'processing') {
            statusDiv.textContent = message;
            statusDiv.className = `status active ${type}`;
        }

        // Convert frequency to nearest pitch in an EDO system
        function freqToEdoStep(freq, referenceHz, edo) {
            const ratio = freq / referenceHz;
            const steps = Math.log2(ratio) * edo;
            return Math.round(steps);
        }

        // Convert EDO step back to frequency
        function edoStepToFreq(step, referenceHz, edo) {
            return referenceHz * Math.pow(2, step / edo);
        }

        // Find nearest pitch in custom scale (in cents)
        function findNearestScalePitch(freq, referenceHz, scaleCents) {
            // Convert frequency to cents from reference
            const cents = 1200 * Math.log2(freq / referenceHz);
            
            // Find octave and position within octave
            const octave = Math.floor(cents / 1200);
            const centsInOctave = cents - (octave * 1200);
            
            // Find nearest scale degree
            let minDiff = Infinity;
            let nearestCents = 0;
            
            for (const scaleCent of scaleCents) {
                const diff = Math.abs(centsInOctave - scaleCent);
                if (diff < minDiff) {
                    minDiff = diff;
                    nearestCents = scaleCent;
                }
            }
            
            // Convert back to frequency
            const totalCents = octave * 1200 + nearestCents;
            return referenceHz * Math.pow(2, totalCents / 1200);
        }

        // Draw spectrogram
        function drawSpectrogram(ctx, specData, width, height) {
            if (specData.length === 0) return;
            
            const timeSteps = specData.length;
            const freqBins = specData[0].length;
            
            // Find max magnitude for normalization
            let maxMag = 0;
            for (let t = 0; t < timeSteps; t++) {
                for (let f = 0; f < freqBins; f++) {
                    maxMag = Math.max(maxMag, specData[t][f]);
                }
            }
            
            // Draw spectrogram
            const pixelWidth = Math.max(1, width / timeSteps);
            const pixelHeight = Math.max(1, height / freqBins);
            
            for (let t = 0; t < timeSteps; t++) {
                for (let f = 0; f < freqBins; f++) {
                    const magnitude = specData[t][f];
                    const normalized = magnitude / (maxMag || 1);
                    
                    // Use log scale for better visibility
                    const intensity = Math.pow(normalized, 0.3) * 255;
                    
                    // Color mapping: blue (low) -> cyan -> yellow -> red (high)
                    let r, g, b;
                    if (intensity < 64) {
                        r = 0;
                        g = 0;
                        b = intensity * 4;
                    } else if (intensity < 128) {
                        r = 0;
                        g = (intensity - 64) * 4;
                        b = 255;
                    } else if (intensity < 192) {
                        r = (intensity - 128) * 4;
                        g = 255;
                        b = 255 - (intensity - 128) * 4;
                    } else {
                        r = 255;
                        g = 255 - (intensity - 192) * 4;
                        b = 0;
                    }
                    
                    ctx.fillStyle = `rgb(${r},${g},${b})`;
                    const x = (t / timeSteps) * width;
                    const y = height - ((f / freqBins) * height); // Flip Y axis
                    ctx.fillRect(x, y, Math.ceil(pixelWidth) + 1, Math.ceil(pixelHeight) + 1);
                }
            }
        }

        // Process audio with frequency separation and approximation
        async function processAudio() {
            try {
                initAudioContext();
                
                const fromEdo = parseInt(fromTetInput.value);
                const toEdo = parseInt(toTetInput.value);
                const initialHz = parseFloat(initialHzInput.value);
                
                // Parse custom scale if provided
                let customScale = null;
                const scaleInput = scaleMakerInput.value.trim();
                if (scaleInput) {
                    try {
                        customScale = scaleInput.split(',').map(s => parseFloat(s.trim())).filter(n => !isNaN(n));
                        if (customScale.length === 0) {
                            customScale = null;
                        } else {
                            // Ensure scale starts at 0 and includes octave (1200)
                            if (!customScale.includes(0)) customScale.unshift(0);
                            if (!customScale.includes(1200)) customScale.push(1200);
                            customScale.sort((a, b) => a - b);
                            showStatus(`Using custom scale with ${customScale.length} steps`, 'processing');
                        }
                    } catch (e) {
                        showStatus('Invalid scale format, using EDO instead', 'processing');
                        customScale = null;
                    }
                }

                showStatus('Extracting audio from video...', 'processing');
                processBtn.disabled = true;

                // Decode video audio
                const arrayBuffer = await videoFile.arrayBuffer();
                const audioBuffer = await decodeAudioFromVideo(arrayBuffer);

                if (!audioBuffer) {
                    throw new Error('Could not extract audio from video');
                }

                showStatus('Analyzing frequencies...', 'processing');

                // Setup spectrograms
                spectrogramContainer.classList.add('active');
                const spectrogramWidth = 800;
                const spectrogramHeight = 200;
                originalCanvas.width = spectrogramWidth;
                originalCanvas.height = spectrogramHeight;
                convertedCanvas.width = spectrogramWidth;
                convertedCanvas.height = spectrogramHeight;
                
                const origCtx = originalCanvas.getContext('2d');
                const convCtx = convertedCanvas.getContext('2d');
                
                // Clear canvases
                origCtx.fillStyle = '#000';
                origCtx.fillRect(0, 0, spectrogramWidth, spectrogramHeight);
                convCtx.fillStyle = '#000';
                convCtx.fillRect(0, 0, spectrogramWidth, spectrogramHeight);

                // Process each channel
                const numChannels = audioBuffer.numberOfChannels;
                const sampleRate = audioBuffer.sampleRate;
                const length = audioBuffer.length;
                const outputChannels = [];
                
                // Store spectrogram data
                const originalSpecData = [];
                const convertedSpecData = [];

                for (let channel = 0; channel < numChannels; channel++) {
                    const channelData = audioBuffer.getChannelData(channel);
                    const outputData = new Float32Array(length);
                    
                    // Process in chunks using FFT
                    const fftSize = 4096;
                    const hopSize = fftSize / 4; // 75% overlap for better time resolution
                    const maxFreqDisplay = 8000; // Display up to 8kHz in spectrogram
                    
                    showStatus(`Processing channel ${channel + 1}/${numChannels}...`, 'processing');
                    
                    let frameIndex = 0;
                    const totalFrames = Math.floor(length / hopSize);
                    const framesPerPixel = Math.max(1, Math.floor(totalFrames / spectrogramWidth));
                    
                    for (let i = 0; i < length; i += hopSize) {
                        const chunk = new Float32Array(fftSize);
                        
                        // Extract chunk with Hann window
                        for (let j = 0; j < fftSize; j++) {
                            const idx = i + j;
                            if (idx < length) {
                                // Apply Hann window
                                const window = 0.5 * (1 - Math.cos(2 * Math.PI * j / fftSize));
                                chunk[j] = channelData[idx] * window;
                            }
                        }
                        
                        // Perform FFT
                        const fft = performFFT(chunk);
                        
                        // Store original spectrogram data (only for first channel and at sampling intervals)
                        if (channel === 0 && frameIndex % framesPerPixel === 0) {
                            const specColumn = [];
                            for (let bin = 0; bin < fftSize / 2; bin++) {
                                const freq = bin * sampleRate / fftSize;
                                if (freq > maxFreqDisplay) break;
                                
                                const real = fft[bin * 2];
                                const imag = fft[bin * 2 + 1];
                                const magnitude = Math.sqrt(real * real + imag * imag);
                                specColumn.push(magnitude);
                            }
                            originalSpecData.push(specColumn);
                        }
                        
                        // Create a copy for converted spectrogram
                        const convertedFFT = new Float32Array(fft.length);
                        for (let j = 0; j < fft.length; j++) {
                            convertedFFT[j] = 0; // Start with silence
                        }
                        
                        // Convert linear spectrum to logarithmic frequency bins
                        const minFreq = 20; // Minimum frequency (Hz)
                        const maxFreq = sampleRate / 2; // Nyquist frequency
                        const numLogBins = 200; // Number of logarithmic bins
                        const logBins = [];
                        
                        // Create logarithmic frequency bins
                        for (let i = 0; i < numLogBins; i++) {
                            const logFreq = minFreq * Math.pow(maxFreq / minFreq, i / (numLogBins - 1));
                            const bin = Math.round(logFreq * fftSize / sampleRate);
                            
                            if (bin < fftSize / 2) {
                                const real = fft[bin * 2];
                                const imag = fft[bin * 2 + 1];
                                const magnitude = Math.sqrt(real * real + imag * imag);
                                const phase = Math.atan2(imag, real);
                                
                                logBins.push({
                                    freq: logFreq,
                                    bin: bin,
                                    magnitude: magnitude,
                                    phase: phase,
                                    real: real,
                                    imag: imag
                                });
                            }
                        }
                        
                        // Detect frequency clusters within 20 cents in logarithmic space
                        const clusters = [];
                        let currentCluster = null;
                        const magnitudeThreshold = 0.001;
                        const centsThreshold = 20; // 20 cents
                        
                        for (const logBin of logBins) {
                            if (logBin.magnitude > magnitudeThreshold) {
                                // Check if this frequency is within 20 cents of current cluster
                                let withinCluster = false;
                                if (currentCluster) {
                                    const lastFreq = currentCluster.lastFreq;
                                    // Calculate cents difference: 1200 * log2(f2/f1)
                                    const centsDiff = Math.abs(1200 * Math.log2(logBin.freq / lastFreq));
                                    withinCluster = centsDiff <= centsThreshold;
                                }
                                
                                if (!currentCluster || !withinCluster) {
                                    // Start new cluster
                                    if (currentCluster) {
                                        clusters.push(currentCluster);
                                    }
                                    currentCluster = {
                                        bins: [logBin.bin],
                                        frequencies: [logBin.freq],
                                        magnitudes: [logBin.magnitude],
                                        phases: [logBin.phase],
                                        reals: [logBin.real],
                                        imags: [logBin.imag],
                                        lastFreq: logBin.freq,
                                        count: 1
                                    };
                                } else {
                                    // Add to current cluster
                                    currentCluster.bins.push(logBin.bin);
                                    currentCluster.frequencies.push(logBin.freq);
                                    currentCluster.magnitudes.push(logBin.magnitude);
                                    currentCluster.phases.push(logBin.phase);
                                    currentCluster.reals.push(logBin.real);
                                    currentCluster.imags.push(logBin.imag);
                                    currentCluster.lastFreq = logBin.freq;
                                    currentCluster.count++;
                                }
                            }
                        }
                        if (currentCluster) {
                            clusters.push(currentCluster);
                        }
                        
                        // Process each cluster with exponential weighting
                        for (const cluster of clusters) {
                            // Calculate weighted center frequency of cluster with exponential weighting
                            let totalMagnitude = 0;
                            let weightedFreqSum = 0;
                            let totalReal = 0;
                            let totalImag = 0;
                            let totalExponentialWeight = 0;
                            
                            for (let i = 0; i < cluster.frequencies.length; i++) {
                                const freq = cluster.frequencies[i];
                                const mag = cluster.magnitudes[i];
                                
                                // Exponential weighting: higher magnitudes get exponentially more weight
                                const expWeight = Math.exp(mag * 2); // Adjust multiplier as needed
                                
                                totalMagnitude += mag;
                                weightedFreqSum += freq * mag * expWeight;
                                totalReal += cluster.reals[i] * expWeight;
                                totalImag += cluster.imags[i] * expWeight;
                                totalExponentialWeight += mag * expWeight;
                            }
                            
                            // Center frequency weighted by magnitude and exponential factor
                            const centerFreq = weightedFreqSum / totalExponentialWeight;
                            const avgPhase = Math.atan2(totalImag, totalReal);
                            
                            // Logarithmic amplification based on cluster size
                            // +10dB for 10 frequencies, +20dB for 100, etc.
                            const dbBoost = 10 * Math.log10(cluster.count);
                            const linearBoost = Math.pow(10, dbBoost / 20); // Convert dB to linear
                            const amplifiedMagnitude = totalMagnitude * linearBoost;
                            
                            // Get processing mode
                            const mode = modeSelect.value;
                            let targetFreq;
                            
                            // Check if both EDOs are in 10-14 range for scale mode
                            const inValidRange = (fromEdo >= 10 && fromEdo <= 14 && toEdo >= 10 && toEdo <= 14);
                            
                            if (mode === 'approximate' || !inValidRange) {
                                // Approximate mode: Round to nearest pitch in target EDO or custom scale
                                // Also used when outside 10-14 EDO range
                                if (customScale) {
                                    // Use custom scale
                                    targetFreq = findNearestScalePitch(centerFreq, initialHz, customScale);
                                } else {
                                    // Use EDO
                                    const targetStep = freqToEdoStep(centerFreq, initialHz, toEdo);
                                    targetFreq = edoStepToFreq(targetStep, initialHz, toEdo);
                                }
                            } else if (mode === 'scale') {
                                // Scale mode: Transform 12x semitones to (fromEdo/toEdo) * 12x semitones
                                // Only for 10-14 EDO
                                // Convert frequency to semitones from reference
                                const semitones = 12 * Math.log2(centerFreq / initialHz);
                                // Scale by ratio fromEdo/toEdo
                                const scaledSemitones = semitones * (fromEdo / toEdo);
                                // Convert back to frequency
                                targetFreq = initialHz * Math.pow(2, scaledSemitones / 12);
                            }
                            
                            const newBin = Math.round(targetFreq * fftSize / sampleRate);
                            
                            if (newBin >= 0 && newBin < fftSize / 2) {
                                // Place entire cluster energy at target bin with amplification
                                convertedFFT[newBin * 2] += amplifiedMagnitude * Math.cos(avgPhase);
                                convertedFFT[newBin * 2 + 1] += amplifiedMagnitude * Math.sin(avgPhase);
                            }
                        }
                        
                        // Store converted spectrogram data
                        if (channel === 0 && frameIndex % framesPerPixel === 0) {
                            const specColumn = [];
                            for (let bin = 0; bin < fftSize / 2; bin++) {
                                const freq = bin * sampleRate / fftSize;
                                if (freq > maxFreqDisplay) break;
                                
                                const real = convertedFFT[bin * 2];
                                const imag = convertedFFT[bin * 2 + 1];
                                const magnitude = Math.sqrt(real * real + imag * imag);
                                specColumn.push(magnitude);
                            }
                            convertedSpecData.push(specColumn);
                        }
                        
                        // Perform inverse FFT
                        const reconstructed = performIFFT(convertedFFT);
                        
                        frameIndex++;
                        
                        // Overlap-add the chunk to output
                        for (let j = 0; j < fftSize && i + j < length; j++) {
                            const window = 0.5 * (1 - Math.cos(2 * Math.PI * j / fftSize));
                            outputData[i + j] += reconstructed[j] * window;
                        }
                    }
                    
                    // Normalize output
                    let maxVal = 0;
                    for (let i = 0; i < length; i++) {
                        maxVal = Math.max(maxVal, Math.abs(outputData[i]));
                    }
                    if (maxVal > 0) {
                        for (let i = 0; i < length; i++) {
                            outputData[i] /= maxVal * 1.1; // Slight headroom
                        }
                    }
                    
                    outputChannels.push(outputData);
                }

                // Draw spectrograms
                showStatus('Rendering spectrograms...', 'processing');
                drawSpectrogram(origCtx, originalSpecData, spectrogramWidth, spectrogramHeight);
                drawSpectrogram(convCtx, convertedSpecData, spectrogramWidth, spectrogramHeight);

                showStatus('Reconstructing audio...', 'processing');

                // Create output buffer
                const outputBuffer = audioContext.createBuffer(numChannels, length, sampleRate);
                for (let channel = 0; channel < numChannels; channel++) {
                    outputBuffer.copyToChannel(outputChannels[channel], channel);
                }

                // Create downloadable file
                const wavBlob = bufferToWave(outputBuffer, outputBuffer.length);
                const url = URL.createObjectURL(wavBlob);
                
                // Create download link
                const a = document.createElement('a');
                a.href = url;
                const mode = modeSelect.value;
                const scaleLabel = customScale ? 'customscale' : `${fromEdo}edo_to_${toEdo}edo`;
                a.download = `converted_${scaleLabel}_${mode}.wav`;
                a.textContent = 'Download Converted Audio';
                a.style.display = 'block';
                a.style.marginTop = '10px';
                a.style.color = '#4a9eff';
                a.style.textDecoration = 'none';
                a.style.fontWeight = 'bold';
                
                statusDiv.innerHTML = '';
                statusDiv.appendChild(document.createTextNode('Conversion complete! '));
                statusDiv.appendChild(a);
                statusDiv.className = 'status active success';

                processBtn.disabled = false;

            } catch (error) {
                console.error('Error processing audio:', error);
                showStatus(`Error: ${error.message}`, 'error');
                processBtn.disabled = false;
            }
        }

        // Simple FFT implementation (Cooley-Tukey algorithm)
        function performFFT(input) {
            const n = input.length;
            const output = new Float32Array(n * 2); // Real and imaginary pairs
            
            // Copy input to output (real part)
            for (let i = 0; i < n; i++) {
                output[i * 2] = input[i];
                output[i * 2 + 1] = 0;
            }
            
            // Bit-reversal permutation
            let j = 0;
            for (let i = 0; i < n; i++) {
                if (i < j) {
                    // Swap
                    let tempReal = output[i * 2];
                    let tempImag = output[i * 2 + 1];
                    output[i * 2] = output[j * 2];
                    output[i * 2 + 1] = output[j * 2 + 1];
                    output[j * 2] = tempReal;
                    output[j * 2 + 1] = tempImag;
                }
                let k = n / 2;
                while (k <= j) {
                    j -= k;
                    k /= 2;
                }
                j += k;
            }
            
            // Cooley-Tukey FFT
            for (let len = 2; len <= n; len *= 2) {
                const halfLen = len / 2;
                const theta = -2 * Math.PI / len;
                
                for (let i = 0; i < n; i += len) {
                    for (let k = 0; k < halfLen; k++) {
                        const angle = theta * k;
                        const wReal = Math.cos(angle);
                        const wImag = Math.sin(angle);
                        
                        const evenIdx = (i + k) * 2;
                        const oddIdx = (i + k + halfLen) * 2;
                        
                        const tReal = wReal * output[oddIdx] - wImag * output[oddIdx + 1];
                        const tImag = wReal * output[oddIdx + 1] + wImag * output[oddIdx];
                        
                        output[oddIdx] = output[evenIdx] - tReal;
                        output[oddIdx + 1] = output[evenIdx + 1] - tImag;
                        output[evenIdx] += tReal;
                        output[evenIdx + 1] += tImag;
                    }
                }
            }
            
            return output;
        }

        // Inverse FFT
        function performIFFT(input) {
            const n = input.length / 2;
            const conjugate = new Float32Array(input.length);
            
            // Conjugate the input
            for (let i = 0; i < n; i++) {
                conjugate[i * 2] = input[i * 2];
                conjugate[i * 2 + 1] = -input[i * 2 + 1];
            }
            
            // Perform FFT on conjugate
            const result = performFFT(conjugate);
            
            // Conjugate and normalize
            const output = new Float32Array(n);
            for (let i = 0; i < n; i++) {
                output[i] = result[i * 2] / n;
            }
            
            return output;
        }

        // Decode audio from video file
        async function decodeAudioFromVideo(arrayBuffer) {
            try {
                // Try to decode directly (works if browser supports the video's audio codec)
                return await audioContext.decodeAudioData(arrayBuffer.slice(0));
            } catch (error) {
                // If direct decode fails, extract using a trick with an audio element
                return await extractAudioViaElement();
            }
        }

        // Alternative method to extract audio
        async function extractAudioViaElement() {
            return new Promise((resolve, reject) => {
                const audio = new Audio(URL.createObjectURL(videoFile));
                
                audio.addEventListener('loadedmetadata', async () => {
                    try {
                        const mediaSource = audioContext.createMediaElementSource(audio);
                        const destination = audioContext.createMediaStreamDestination();
                        mediaSource.connect(destination);
                        
                        const mediaRecorder = new MediaRecorder(destination.stream);
                        const chunks = [];
                        
                        mediaRecorder.ondataavailable = (e) => chunks.push(e.data);
                        mediaRecorder.onstop = async () => {
                            const blob = new Blob(chunks, { type: 'audio/webm' });
                            const arrayBuffer = await blob.arrayBuffer();
                            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                            resolve(audioBuffer);
                        };
                        
                        mediaRecorder.start();
                        audio.play();
                        
                        setTimeout(() => {
                            audio.pause();
                            mediaRecorder.stop();
                        }, audio.duration * 1000);
                        
                    } catch (error) {
                        reject(error);
                    }
                });
                
                audio.addEventListener('error', reject);
            });
        }

        // Convert AudioBuffer to WAV file
        function bufferToWave(abuffer, len) {
            const numOfChan = abuffer.numberOfChannels;
            const length = len * numOfChan * 2 + 44;
            const buffer = new ArrayBuffer(length);
            const view = new DataView(buffer);
            const channels = [];
            let offset = 0;
            let pos = 0;

            // Write WAV header
            setUint32(0x46464952); // "RIFF"
            setUint32(length - 8); // file length - 8
            setUint32(0x45564157); // "WAVE"
            setUint32(0x20746d66); // "fmt " chunk
            setUint32(16); // length = 16
            setUint16(1); // PCM (uncompressed)
            setUint16(numOfChan);
            setUint32(abuffer.sampleRate);
            setUint32(abuffer.sampleRate * 2 * numOfChan); // avg. bytes/sec
            setUint16(numOfChan * 2); // block-align
            setUint16(16); // 16-bit
            setUint32(0x61746164); // "data" - chunk
            setUint32(length - pos - 4); // chunk length

            // Write interleaved data
            for (let i = 0; i < abuffer.numberOfChannels; i++) {
                channels.push(abuffer.getChannelData(i));
            }

            while (pos < len) {
                for (let i = 0; i < numOfChan; i++) {
                    let sample = Math.max(-1, Math.min(1, channels[i][pos]));
                    sample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
                    view.setInt16(offset, sample, true);
                    offset += 2;
                }
                pos++;
            }

            return new Blob([buffer], { type: 'audio/wav' });

            function setUint16(data) {
                view.setUint16(offset, data, true);
                offset += 2;
            }

            function setUint32(data) {
                view.setUint32(offset, data, true);
                offset += 4;
            }
        }

        // Process button click handler
        processBtn.addEventListener('click', processAudio);
    </script>
</body>
</html>
